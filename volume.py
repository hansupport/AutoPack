import pyrealsense2 as rs
import open3d as o3d
import numpy as np
import time

# --- [1] ì‚¬ìš©ì ì„¤ì •: ê´€ì‹¬ ì˜ì—­(ROI) ë° ë°”ë‹¥ ì œê±° ---
ROI_BOUNDS = {
    "min_x": -0.3,  # ROIì˜ ì™¼ìª½ ê²½ê³„
    "max_x": 0.3,   # ROIì˜ ì˜¤ë¥¸ìª½ ê²½ê³„
    "min_y": -0.3,  # ROIì˜ ìœ„ìª½ ê²½ê³„
    "max_y": 0.3,   # ROIì˜ ì•„ë˜ìª½ ê²½ê³„
    "min_z": 0.5,   # ROIì˜ ì•ìª½(ì¹´ë©”ë¼ì— ê°€ê¹Œìš´) ê²½ê³„
    "max_z": 0.8    # ROIì˜ ë’¤ìª½(ì¹´ë©”ë¼ì—ì„œ ë¨¼) ê²½ê³„
}
PLANE_DISTANCE_THRESHOLD = 0.01
MIN_PLANE_RATIO = 0.2

# --- CUDA ì¥ì¹˜ ì„¤ì • ---
if o3d.core.cuda.is_available():
    device = o3d.core.Device("CUDA:0")
    print("Open3Dì—ì„œ CUDAë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    device = o3d.core.Device("CPU:0")
    print("CUDAë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# --- [2] í•¨ìˆ˜ ì •ì˜ ì˜ì—­ ---
def create_pipeline(serial):
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_device(serial)
    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
    pipeline.start(config)
    return pipeline

def get_intrinsics(pipeline):
    profile = pipeline.get_active_profile()
    intr = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()
    return o3d.camera.PinholeCameraIntrinsic(
        intr.width, intr.height, intr.fx, intr.fy, intr.ppx, intr.ppy
    )

def get_pointcloud(pipeline, intrinsic, align, filters):
    try:
        frames = pipeline.wait_for_frames(timeout_ms=1000)
    except RuntimeError:
        return None # ì˜¤ë¥˜ ë°œìƒ ì‹œ None ë°˜í™˜
    
    aligned_frames = align.process(frames)
    depth_frame = aligned_frames.get_depth_frame()
    if not depth_frame:
        return None
        
    for f in filters:
        depth_frame = f.process(depth_frame)
        
    depth_image = o3d.geometry.Image(np.asanyarray(depth_frame.get_data()))
    pcd = o3d.geometry.PointCloud.create_from_depth_image(
        depth_image, intrinsic, depth_scale=1000.0, depth_trunc=3.0
    )
    return pcd

# --- [3] ë©”ì¸ ì‹¤í–‰ ì˜ì—­ ---
pipelines = []
vis = o3d.visualization.Visualizer()
is_vis_initialized = False

try:
    ctx = rs.context()
    serials = [dev.get_info(rs.camera_info.serial_number) for dev in ctx.query_devices()]
    if len(serials) < 2:
        raise RuntimeError("2ëŒ€ ì´ìƒì˜ RealSense ì¹´ë©”ë¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    print("ì—°ê²°ëœ ì¹´ë©”ë¼:", serials)
    pipelines = [create_pipeline(s) for s in serials]
    depth_filters = [rs.decimation_filter(), rs.spatial_filter(), rs.temporal_filter(), rs.hole_filling_filter()]

    print("ì¹´ë©”ë¼ ì„¼ì„œ ì•ˆì •í™”ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°í•©ë‹ˆë‹¤...")
    for _ in range(30):
        for pipe in pipelines:
            pipe.wait_for_frames()
    print("ì•ˆì •í™” ì™„ë£Œ.")

    intrinsics = [get_intrinsics(p) for p in pipelines]
    align_to_color = rs.align(rs.stream.color)
    transform_matrix_cpu = np.load('transform_matrix.npy')
    transform_matrix_gpu = o3d.core.Tensor(transform_matrix_cpu, o3d.core.float64, device)
    
    print(f"transform_matrix.npy íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    is_vis_initialized = vis.create_window(window_name="Real-time Size Estimation (3D BBox)", width=1280, height=720)
    if not is_vis_initialized:
        print("[ê²½ê³ ] Open3D ì‹œê°í™” ì°½ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


    min_bound_cpu = [ROI_BOUNDS["min_x"], ROI_BOUNDS["min_y"], ROI_BOUNDS["min_z"]]
    max_bound_cpu = [ROI_BOUNDS["max_x"], ROI_BOUNDS["max_y"], ROI_BOUNDS["max_z"]]
    roi_bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound_cpu, max_bound=max_bound_cpu)
    roi_bbox.color = (0, 1, 0) # ROIëŠ” ì´ˆë¡ìƒ‰

    roi_bbox_t = o3d.t.geometry.AxisAlignedBoundingBox.from_legacy(roi_bbox, device=device)

    while True:
        pcd1_cpu = get_pointcloud(pipelines[0], intrinsics[0], align_to_color, depth_filters)
        pcd2_cpu = get_pointcloud(pipelines[1], intrinsics[1], align_to_color, depth_filters)

        if is_vis_initialized:
            vis.clear_geometries()
            vis.add_geometry(roi_bbox)

        if pcd1_cpu is None or pcd2_cpu is None or pcd1_cpu.is_empty() or pcd2_cpu.is_empty():
            if is_vis_initialized and not vis.poll_events(): break
            if is_vis_initialized: vis.update_renderer()
            continue
        
        pcd1_t = o3d.t.geometry.PointCloud.from_legacy(pcd1_cpu, device=device)
        pcd2_t = o3d.t.geometry.PointCloud.from_legacy(pcd2_cpu, device=device)
        
        pcd2_t.transform(transform_matrix_gpu)
        merged_t = pcd1_t + pcd2_t
        pcd_cropped_t = merged_t.crop(roi_bbox_t)
        
        object_detected = False
        if len(pcd_cropped_t.point["positions"]) > 0:
            
            # ë°˜ë³µì  í‰ë©´ ì œê±° ë¡œì§
            remaining_pcd_t = pcd_cropped_t
            min_points_in_plane = int(len(remaining_pcd_t.point["positions"]) * MIN_PLANE_RATIO)

            while len(remaining_pcd_t.point["positions"]) > min_points_in_plane:
                try:
                    _, inliers = remaining_pcd_t.segment_plane(
                        distance_threshold=PLANE_DISTANCE_THRESHOLD,
                        ransac_n=3,
                        num_iterations=100
                    )
                    if len(inliers) < min_points_in_plane:
                        break
                    remaining_pcd_t = remaining_pcd_t.select_by_index(inliers, invert=True)
                except Exception:
                    break
            object_pcd_t = remaining_pcd_t

            if len(object_pcd_t.point["positions"]) > 0:
                labels = object_pcd_t.cluster_dbscan(eps=0.02, min_points=10, print_progress=False)
                counts = np.bincount(labels.cpu().numpy()[labels.cpu().numpy() >= 0])
                if len(counts) > 0:
                    largest_cluster_label = counts.argmax()
                    
                    indices_np = np.where(labels.cpu().numpy() == largest_cluster_label)[0]
                    indices_t = o3d.core.Tensor(indices_np, dtype=o3d.core.int64, device=device)
                    final_object_pcd_t = object_pcd_t.select_by_index(indices_t)
                    
                    if len(final_object_pcd_t.point["positions"]) > 0:
                        final_object_pcd_cpu = final_object_pcd_t.to_legacy()
                        
                        # 3D ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                        oriented_bbox = final_object_pcd_cpu.get_oriented_bounding_box()
                        dims_sorted = sorted(oriented_bbox.extent, reverse=True)
                        length, width, height = dims_sorted[0], dims_sorted[1], dims_sorted[2]
                        print(f"\rğŸ“ ìµœì¢… ë¬¼ì²´ í¬ê¸° (m): L={length:.3f}, W={width:.3f}, H={height:.3f}", end="")
                        
                        oriented_bbox.color = (1, 0, 0) # ë°”ìš´ë”© ë°•ìŠ¤ëŠ” ë¹¨ê°„ìƒ‰
                        
                        if is_vis_initialized:
                            vis.add_geometry(final_object_pcd_cpu)
                            vis.add_geometry(oriented_bbox)
                        object_detected = True
        
        if not object_detected:
            print("\r" + " " * 80, end="")

        if is_vis_initialized and not vis.poll_events():
            break
        if is_vis_initialized: vis.update_renderer()

except (KeyboardInterrupt, SystemExit):
    print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
except Exception as e:
    import traceback
    print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
    traceback.print_exc()
finally:
    for pipe in pipelines:
        pipe.stop()
    if is_vis_initialized:
        vis.destroy_window()
    print("\nì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")